{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA05-A - Logistic Regression\n",
    "### Vania Revelina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# read data into a pandas dataframe called cvd\n",
    "cvd = pd.read_csv('https://github.com/ArinB/CA05-B-Logistic-Regression/raw/master/cvd_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvd_4types</th>\n",
       "      <th>age_s1</th>\n",
       "      <th>race</th>\n",
       "      <th>educat</th>\n",
       "      <th>mstat</th>\n",
       "      <th>hip</th>\n",
       "      <th>neck20</th>\n",
       "      <th>waist</th>\n",
       "      <th>av_weight_kg</th>\n",
       "      <th>cgpkyr</th>\n",
       "      <th>tea15</th>\n",
       "      <th>srhype</th>\n",
       "      <th>parrptdiab</th>\n",
       "      <th>bend25</th>\n",
       "      <th>happy25</th>\n",
       "      <th>tired25</th>\n",
       "      <th>hlthlm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>113.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>83.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>105.0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>49.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>129.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>89.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>81.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>140.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>101.0</td>\n",
       "      <td>87.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>107.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>79.1</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>105.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>90.0</td>\n",
       "      <td>78.1</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cvd_4types  age_s1  race  educat  mstat    hip  neck20  waist  \\\n",
       "0           0      54     1       2      1  110.0    40.0  108.0   \n",
       "1           0      56     3       2      1  113.0    34.0  107.0   \n",
       "2           0      54     1       3      1  110.0    44.5  105.0   \n",
       "3           0      54     1       3      1  129.0    42.5  110.0   \n",
       "4           0      51     3       2      1  122.0    37.0  113.0   \n",
       "5           0      67     1       3      3  140.0    35.5  101.0   \n",
       "6           0      68     1       2      1  101.0    39.0   93.0   \n",
       "7           0      67     1       2      1  107.0    32.0   80.0   \n",
       "8           0      44     1       2      1  100.0    36.5   89.0   \n",
       "9           0      42     1       2      1  105.0    35.5   90.0   \n",
       "\n",
       "   av_weight_kg  cgpkyr  tea15  srhype  parrptdiab  bend25  happy25  tired25  \\\n",
       "0          87.5   34.00      0       1           0       1        2        3   \n",
       "1          83.5    0.00      0       0           0       2        2        1   \n",
       "2          86.2   49.50      0       0           0       3        2        6   \n",
       "3          89.1    0.00      0       0           0       3        2        1   \n",
       "4          81.3    0.00      0       0           0       2        1        1   \n",
       "5          87.2    0.00      0       1           0       1        1        4   \n",
       "6          80.5    9.20      0       0           0       2        3        4   \n",
       "7          73.2    0.00      0       1           0       2        2        4   \n",
       "8          79.1    6.75      0       0           0       3        3        4   \n",
       "9          78.1   21.00      0       0           0       3        2        3   \n",
       "\n",
       "   hlthlm25  \n",
       "0         4  \n",
       "1         3  \n",
       "2         4  \n",
       "3         3  \n",
       "4         2  \n",
       "5         4  \n",
       "6         4  \n",
       "7         4  \n",
       "8         4  \n",
       "9         3  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the first 5 rows to see a glimpse of the data structure\n",
    "cvd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3242 entries, 0 to 3241\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   cvd_4types    3242 non-null   int64  \n",
      " 1   age_s1        3242 non-null   int64  \n",
      " 2   race          3242 non-null   int64  \n",
      " 3   educat        3242 non-null   int64  \n",
      " 4   mstat         3242 non-null   int64  \n",
      " 5   hip           3242 non-null   float64\n",
      " 6   neck20        3242 non-null   float64\n",
      " 7   waist         3242 non-null   float64\n",
      " 8   av_weight_kg  3242 non-null   float64\n",
      " 9   cgpkyr        3242 non-null   float64\n",
      " 10  tea15         3242 non-null   int64  \n",
      " 11  srhype        3242 non-null   int64  \n",
      " 12  parrptdiab    3242 non-null   int64  \n",
      " 13  bend25        3242 non-null   int64  \n",
      " 14  happy25       3242 non-null   int64  \n",
      " 15  tired25       3242 non-null   int64  \n",
      " 16  hlthlm25      3242 non-null   int64  \n",
      "dtypes: float64(5), int64(12)\n",
      "memory usage: 430.7 KB\n"
     ]
    }
   ],
   "source": [
    "# call the info() method to see the column details and data types\n",
    "cvd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cvd_4types</th>\n",
       "      <th>age_s1</th>\n",
       "      <th>race</th>\n",
       "      <th>educat</th>\n",
       "      <th>mstat</th>\n",
       "      <th>hip</th>\n",
       "      <th>neck20</th>\n",
       "      <th>waist</th>\n",
       "      <th>av_weight_kg</th>\n",
       "      <th>cgpkyr</th>\n",
       "      <th>tea15</th>\n",
       "      <th>srhype</th>\n",
       "      <th>parrptdiab</th>\n",
       "      <th>bend25</th>\n",
       "      <th>happy25</th>\n",
       "      <th>tired25</th>\n",
       "      <th>hlthlm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "      <td>3242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.590068</td>\n",
       "      <td>64.828809</td>\n",
       "      <td>1.094695</td>\n",
       "      <td>2.326342</td>\n",
       "      <td>1.368600</td>\n",
       "      <td>105.404832</td>\n",
       "      <td>37.550719</td>\n",
       "      <td>97.209904</td>\n",
       "      <td>82.945928</td>\n",
       "      <td>12.904010</td>\n",
       "      <td>0.430907</td>\n",
       "      <td>0.327884</td>\n",
       "      <td>0.067551</td>\n",
       "      <td>2.473782</td>\n",
       "      <td>2.281308</td>\n",
       "      <td>4.292721</td>\n",
       "      <td>3.864898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.491897</td>\n",
       "      <td>10.400496</td>\n",
       "      <td>0.358237</td>\n",
       "      <td>0.697934</td>\n",
       "      <td>0.933871</td>\n",
       "      <td>10.280402</td>\n",
       "      <td>4.101003</td>\n",
       "      <td>13.598060</td>\n",
       "      <td>7.849650</td>\n",
       "      <td>20.156736</td>\n",
       "      <td>1.242444</td>\n",
       "      <td>0.469515</td>\n",
       "      <td>0.251012</td>\n",
       "      <td>0.672158</td>\n",
       "      <td>0.951695</td>\n",
       "      <td>1.021099</td>\n",
       "      <td>0.614247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>57.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>34.425000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>78.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>37.150000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>82.550000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>86.575000</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>136.700000</td>\n",
       "      <td>170.500000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cvd_4types       age_s1         race       educat        mstat  \\\n",
       "count  3242.000000  3242.000000  3242.000000  3242.000000  3242.000000   \n",
       "mean      0.590068    64.828809     1.094695     2.326342     1.368600   \n",
       "std       0.491897    10.400496     0.358237     0.697934     0.933871   \n",
       "min       0.000000    39.000000     1.000000     1.000000     1.000000   \n",
       "25%       0.000000    57.000000     1.000000     2.000000     1.000000   \n",
       "50%       1.000000    65.000000     1.000000     2.000000     1.000000   \n",
       "75%       1.000000    73.000000     1.000000     3.000000     1.000000   \n",
       "max       1.000000    90.000000     3.000000     4.000000     8.000000   \n",
       "\n",
       "               hip       neck20        waist  av_weight_kg       cgpkyr  \\\n",
       "count  3242.000000  3242.000000  3242.000000   3242.000000  3242.000000   \n",
       "mean    105.404832    37.550719    97.209904     82.945928    12.904010   \n",
       "std      10.280402     4.101003    13.598060      7.849650    20.156736   \n",
       "min      44.000000    25.000000    67.000000     57.400000     0.000000   \n",
       "25%      99.000000    34.425000    88.000000     78.200000     0.000000   \n",
       "50%     104.000000    37.150000    97.000000     82.550000     0.300000   \n",
       "75%     110.000000    40.500000   106.000000     86.575000    20.475000   \n",
       "max     168.000000    53.000000   135.000000    136.700000   170.500000   \n",
       "\n",
       "             tea15       srhype   parrptdiab       bend25      happy25  \\\n",
       "count  3242.000000  3242.000000  3242.000000  3242.000000  3242.000000   \n",
       "mean      0.430907     0.327884     0.067551     2.473782     2.281308   \n",
       "std       1.242444     0.469515     0.251012     0.672158     0.951695   \n",
       "min       0.000000     0.000000     0.000000     1.000000     1.000000   \n",
       "25%       0.000000     0.000000     0.000000     2.000000     2.000000   \n",
       "50%       0.000000     0.000000     0.000000     3.000000     2.000000   \n",
       "75%       0.000000     1.000000     0.000000     3.000000     3.000000   \n",
       "max      30.000000     1.000000     1.000000     3.000000     6.000000   \n",
       "\n",
       "           tired25     hlthlm25  \n",
       "count  3242.000000  3242.000000  \n",
       "mean      4.292721     3.864898  \n",
       "std       1.021099     0.614247  \n",
       "min       1.000000     1.000000  \n",
       "25%       4.000000     4.000000  \n",
       "50%       4.000000     4.000000  \n",
       "75%       5.000000     4.000000  \n",
       "max       6.000000     5.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the description of all variables\n",
    "cvd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Logistic Regression\n",
    "Build a binary classifier model to predict the CVD Risk (Yes/No, or 1/0) using a Logistic Regression Model with the best performance possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummy variables for all the categoricals ('race','educat','mstat','srhype','parrptdiab','bend25','happy25','tired25','hlthlm25')\n",
    "cvd = pd.get_dummies(data=cvd, columns=['race','educat','mstat','srhype','parrptdiab','bend25','happy25','tired25','hlthlm25'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 10000.0\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# split dataset into train set: independent (X_train) and dependent (y_train)\n",
    "# and test set: independent (X_test) and dependent (y_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(cvd.drop('cvd_4types',axis=1),cvd['cvd_4types'], test_size=0.3, random_state=23)\n",
    "\n",
    "# instantiate logistic regression model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=23)\n",
    "\n",
    "# specify hyperparameter values to try to put into the logistic regression model\n",
    "grid_values = {'penalty': ['l1','l2'], 'C': np.logspace(-4, 4, 20)}\n",
    "\n",
    "# use GridSearchCV to try out each of the grid values as hyperparameters for the logistic regression model\n",
    "clf = GridSearchCV(logreg, param_grid = grid_values, cv = 5)\n",
    "\n",
    "# fit to get best model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.51      0.61       404\n",
      "           1       0.72      0.88      0.79       569\n",
      "\n",
      "    accuracy                           0.73       973\n",
      "   macro avg       0.73      0.69      0.70       973\n",
      "weighted avg       0.73      0.73      0.71       973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# print classification report for future comparison\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 0.615848211066026\n"
     ]
    }
   ],
   "source": [
    "# instantiate a second logistic regression with a different solver: newton-cg\n",
    "# newton-cg solver only works for 'l2' penalty, this is why we cannot put this solver together\n",
    "# with liblinear when trying out hyperparameters for GridSearchCV\n",
    "logreg2 = LogisticRegression(solver='newton-cg',penalty='l2', random_state=23)\n",
    "\n",
    "# specify hyperparameter values to try\n",
    "grid_values2 = {'C': np.logspace(-4, 4, 20)}\n",
    "\n",
    "# use GridSearchCV to try out the values\n",
    "clf2 = GridSearchCV(logreg2, param_grid = grid_values2, cv = 5)\n",
    "\n",
    "# fit to get the best model\n",
    "best_model2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "# print the best hyperparameter\n",
    "print('Best C:', best_model2.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.51      0.61       404\n",
      "           1       0.72      0.88      0.79       569\n",
      "\n",
      "    accuracy                           0.73       973\n",
      "   macro avg       0.74      0.70      0.70       973\n",
      "weighted avg       0.73      0.73      0.72       973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "y_pred2 = best_model2.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 Conclusion\n",
    "Seems that the F1-score for class 1 is the same for either hyperparameters. For simplicity, we will be using the following hyperparameters going forward:\n",
    "* solver = 'newton-cg'\n",
    "* penalty = 'l2'\n",
    "* C = 0.616"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Importance\n",
    "Display the Feature Importance of all the features sorted in the order of decreasing influence on the CVD Risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race_3          2.165701\n",
       "mstat_4         1.611206\n",
       "hlthlm25_5      1.456916\n",
       "educat_4        1.220265\n",
       "mstat_8         0.957383\n",
       "parrptdiab_1    0.824542\n",
       "hlthlm25_4      0.659768\n",
       "hlthlm25_2      0.623591\n",
       "mstat_2         0.534007\n",
       "hlthlm25_3      0.443619\n",
       "happy25_6       0.439732\n",
       "race_2          0.416702\n",
       "mstat_3         0.325098\n",
       "educat_2        0.296953\n",
       "tired25_3       0.276107\n",
       "tired25_6       0.266860\n",
       "tired25_5       0.242009\n",
       "bend25_3        0.186483\n",
       "happy25_3       0.167413\n",
       "happy25_5       0.167281\n",
       "tired25_2       0.158044\n",
       "tired25_4       0.150045\n",
       "happy25_2       0.086249\n",
       "waist           0.078291\n",
       "hip             0.058179\n",
       "tea15           0.052847\n",
       "happy25_4       0.047819\n",
       "neck20          0.035015\n",
       "av_weight_kg    0.021405\n",
       "educat_3        0.009379\n",
       "age_s1          0.005803\n",
       "bend25_2        0.004503\n",
       "cgpkyr          0.001332\n",
       "srhype_1        0.000142\n",
       "Name: coefficients, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate best logistic regression model\n",
    "best_model = LogisticRegression(solver='newton-cg', penalty='l2', C=0.616, random_state=23)\n",
    "# fit training set\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# get coefficients and assign it into a pandas series\n",
    "coefs = pd.Series(best_model.coef_[0], index = X_train.columns, name='coefficients')\n",
    "# the sign of each coefficient is only an indication of positive or negative correlation,\n",
    "# the higher the absolute values of the correlation coefficient, the higher the influence\n",
    "# of the feature to the dependent variable.\n",
    "# Because of this, we apply a lambda function to the series to only get the absolute values for each coefficient.\n",
    "coefs = coefs.apply(lambda x: abs(x))\n",
    "# display the series in a descending order of influence\n",
    "coefs.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Evaluate Performance\n",
    "Evaluate the performance of your model (including ROC Curve), explain the performance and draw a meaningful conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true negatives: 205\n",
      "false positives: 199\n",
      "false negatives: 66\n",
      "true positives: 503\n",
      "===================================\n",
      "precision: 0.72\n",
      "recall: 0.88\n",
      "f1-score: 0.79\n",
      "===================================\n",
      "AUC (Area Under Curve): 0.7543980232821172\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3dd1zV9ffA8RfciyKKylAR5YuI4iInpuICIdtlllYuyJa5B6K4cefKHKmp4UhzpbZ+meGInFmu1G/J0BTBAaiggHC5n98f5v2KDC8Id3Gej0ePuPd+7r3n7dV7eK/ztlIURUEIIYQArI0dgBBCCNMhSUEIIYSOJAUhhBA6khSEEELoSFIQQgihI0lBCCGEjiQFIYQQOpIUhFkLDg7GysoKKysrVCoVtWvXpl+/fly5ciXPtbGxsQQHB1OrVi3KlSuHq6srQUFBxMbG5rk2PT2d6dOn07RpU+zs7HB0dKRNmzYsXryY9PT0QmM6e/Ysffv2pVatWpQvXx53d3dee+019u3bV2LtFqK0SFIQZq9jx44kJiZy6dIlNm7cyIkTJ+jRo0eua06cOIGPjw/x8fFs3LiRmJgYNm3aREJCAj4+Ppw8eVJ3bWpqKu3bt2fx4sUMGjSIQ4cO8ccffxASEsKWLVvYvXt3gbH89NNP+Pj4kJCQwKpVqzh37hzfffcdbdu25cMPP3yidmZlZT3R84XQiyKEGQsKClICAgJy3bdo0SIFUG7fvq0oiqJotVqladOmylNPPaVkZ2fnujY7O1vx9vZWmjVrpmi1WkVRFGXw4MGKra2tEhcXl+f9tFqtcvPmzXxjuXv3rlK9enXlueeey/fxlJQU3c+Asn79+lyPBwQEKEFBQbrb7u7uyvjx45WPPvpIcXR0VJ5++mmlV69eyjPPPJPntZ977jmld+/eutu7d+9WfH19FVtbW8XV1VUJDg5WkpKS8o1LiIdJT0FYlISEBLZt24ZKpUKlUgFw+vRpTp8+TWhoKGq1Otf1arWa0NBQTp06xZ9//olWq2XDhg307t0bDw+PPK9vZWVF1apV833v3bt3c/36dcaPH5/v4w4ODkVuz6JFi6hevTqHDx8mIiKCoKAg9uzZQ0JCgu6axMREfv75Z/r16wfA3r17efXVV3nrrbc4ffo0O3fu5OLFi3Tv3h1FqtqIx1A//hIhTNv+/fupVKkSWq2WjIwMAEaNGkXFihUB+PvvvwFo0qRJvs9/cP/ff/+Ni4sLN2/epHHjxkWO4/z58wDFem5BWrduzZQpU3S3GzZsiIuLCxs2bGD06NEAbNiwARcXFwIDAwGYOnUqQ4cOZciQIbrnrV27Fnd3d06dOkXz5s1LLD5heaSnIMxemzZtOHnyJL/99hsTJ06kXbt2TJ8+vViv9SS/SZfGb+FPP/10rtvW1tb06dOH9evX6+5bv349vXv3xtr6/j/nY8eOsXDhQipVqqT770Giio6OLvEYhWWRnoIwexUqVKBevXoAeHt7Exsby5AhQ1i5ciUAXl5eAJw5c4YWLVrkef7Zs2cBaNCgAdWqVcPBwYFz584VOY4GDRoAcO7cOTp06FDotVZWVnmSSHZ2dp7rHvR2HtavXz/mzJmjmxw/ffo0X331le5xrVbLmDFj6Nu3b57nuri4PL4hokyTnoKwOFOmTCEiIoLff/8dgGbNmuHt7c3cuXPRaDS5rtVoNMydO5emTZvy1FNPYW1tTa9evdiwYQMXLlzI89qKonD79u1837dr165Ur16dGTNm5Pv4zZs3dT9Xr14917zAvXv39E5ETZo0oVWrVqxfv55169bRqlWrXENWPj4+nD17lnr16uX5r1KlSnq9hyi7JCkIi1O/fn1efvll3YSvlZUVa9as4Z9//uH5558nKiqKy5cv8+uvv/LCCy9w6dIl1qxZg5WVFQAzZsygfv36tG3bls8//5xTp05x4cIFduzYQefOnQvcb2BnZ8eaNWvYt28fgYGB/Pjjj8TFxfHnn38yb9482rZtq7s2MDCQ5cuXc/jwYc6cOUNwcHCRlpz269ePjRs38tVXXxEUFJTrsalTp/LNN98wcuRITp48SWxsLLt27eLdd9/VzbkIUSCjrn0S4gnltyRVURTl4MGDCqDs27dPd9/58+eVfv36KTVr1lTUarXi4uKi9OvXT4mJicnz/Dt37ijh4eGKt7e3Ymtrq1StWlV5+umnlSVLlijp6emFxnT69GmlV69eSs2aNRUbGxvFzc1Nee2115RffvlFd01iYqLy0ksvKfb29krt2rWVzz77LN8lqdOmTcv3PW7cuKHY2NgoNjY2yo0bN/I8HhUVpQQEBCiVKlVS7OzslIYNGyrDhg3LsyRXiEdZKYqsURNCCHGfDB8JIYTQkaQghBBCR5KCEEIIHUkKQgghdCQpCCGE0DH7Hc0PbwAqCmdnZ5KSkko4GtMmbS4bpM1lw5O02dXVtcDHpKcghBBCR5KCEEIIHUkKQgghdCQpCCGE0JGkIIQQQscgq48+++wzjh8/TpUqVZg/f36exxVFISIighMnTlC+fHkGDhxI3bp1DRGaEEKIhxikp+Dn58e4ceMKfPzEiRNcvXqVRYsW8cEHH7Bq1SpDhCWEEOIRBkkKjRs3LvRwj99//51OnTphZWWFl5cXd+/ezXUgiRBCiPsyI78lffoo0lYvLJXXN4nNaykpKTg7O+tuOzk5kZKSgoODQ55rIyMjiYyMBGD27Nm5nlcUarW62M81V9LmskHabPrSd+8kM+rnIj/v1q1bVLzy74mATVuWSptNIikURWBgIIGBgbrbxd3RJzsgywZpc9lgrDZro3ahHI0q+hPPn7n/fy9vvS7P0Wj4559/uHb9Ora2tlR95mXa9h9WKjuaTSIpODo65mpccnIyjo6ORoxICGFJiv3l/ThF/HLX8fLGqk0nrDs999hLc3Jy6BoQQGxsLAMGDGDkyJFUqFChGMHqxySSgo+PD7t27aJ9+/ZER0djZ2eX79CREEIUpNAv/uJ+eT9OEb7ci+rBELpKpWLMmDG4urrSrFmzEn+fRxkkKSxcuJBz586RlpbGgAED6NmzJxqNBoCuXbvSokULjh8/ztChQylXrhwDBw40RFhCCDNS2Jd+io0NytkT92/k98Vfil/eJU1RFLZv386kSZMYN24cvXv35vnnnzfY+xskKQwfPrzQx62srHjvvfcMEYoQwkQUeUjncb/tm9EXf0GuXLnC2LFj2bt3Ly1btqR169YGj8Ekho+EEOatWGP2RR3SKeRL39ECJtd37tzJmDFjyMnJITw8nHfeeQeVSmXwOCQpCCEe67Ff+sUZs7eA3+xLUpUqVWjRogVz5szhP//5j9HikKQghMgjTxIoA0M3hqbRaFi5ciVZWVkMGzYMf39//Pz8sLKyMmpckhSEsHAlMrQjX/ol6uzZs4SEhHD69GlefvllFEXBysrK6AkBJCkIYXHSd+8kZ8///e8OGdoxGffu3ePTTz9l6dKlVK1alRUrVvDiiy+aRDJ4QJKCEGbu0Z5AmvyWb7IuXLjAZ599Rrdu3Zg8ebJJbtKVpCCEmVOORsHlC+DmAYBNkxZoWraTJGAi7t69y08//UT37t1p2LAhv/zyC+7u7sYOq0CSFIQwQ7l6B/8mBNXomYBlLM+0FFFRUYSGhhIfH89TTz1F/fr1TTohgJy8JoTZ0UbtQln/2f/mCtw8sGrTybhBiVxu3brFqFGjePvtt7GxseHrr7+mfv36xg5LL9JTEMKE6LVS6N9kYNV3oAwRmaCcnBy6detGXFwcgwcPZsSIEdja2ho7LL1JUhDChDw6P5AvmTg2SSkpKVStWhWVSsXYsWOpVasWTz31lLHDKjJJCkKYmofmB4TpUxSFbdu2MWXKFMLCwujTpw/PPWe+CVuSghAmQDds9LhegjAp8fHxjBkzhv379+Pj40Pbtm2NHdITk6QghBHpksFDewtk0tg8fP3114SFhaEoCtOnTycoKAhra/NfuyNJQYhSoHdpiUeSgcwTmA8nJydat27Nxx9/TO3atY0dTomRpCBECcrvN/9CSTIwG9nZ2axYsYLs7GxGjBiBn58fnTt3NqkSFSVBkoIQJUS3fwDky97CnDlzhlGjRnHmzBleffVVkypgV9IkKQhRQh4MF8n+AcuRmZnJJ598wrJly3B0dGTlypW88MILxg6rVJn/rIgQpsTLWxKCBbl48SIrVqzgjTfeYP/+/RafEECSghAlQhu163/zCMKs3b17l23btgHQsGFDoqKiWLBgAVWrVjVyZIYhSUGIEqAbOpLlpGZt//79+Pv7M3z4cKKjowGMejSmMcicghDFlKdSqQwdma2UlBTCw8PZtm0b9erVY8eOHWZTwK6kSVIQoojyXXYqlUrN1oMCdhcvXmTo0KEMGzbMrArYlTRJCkIUgSw7tRzJyck4ODigUqkYP348tWrVwtu7CEeWWihJCkLo4dHegSw7NV+KorBlyxbCw8MJCwujb9++PPvss8YOy2RIUhDiMaR3YDkuX75MaGgoUVFRtGnTBl9fX2OHZHIkKQiRj1yTyNI7sAjbtm0jLCwMKysrZs6cSd++fS2igF1Jk6QgxEPynUSW3oFFqFatGm3btmX27NnUqlXL2OGYLEkKoszLr1cgicD8ZWdn89lnn6HVahkxYgSdO3emc+fOxg7L5ElSEGVersNtJBlYhD///JORI0dy7tw5XnvtNV0BO/F4khREmfXoaWdyBKb5y8jI4JNPPmH58uU4OTmxevVqsz4a0xgMlhROnjxJREQEWq2WgIAAunXrluvxpKQkli5dyt27d9FqtfTq1YuWLVsaKjxh4fI99EZOO7M4ly5d4vPPP6dnz55MmDChzNQrKkkGSQparZbVq1czYcIEnJycCAsLw8fHJ9dpRV9//TXt2rWja9euxMfHM2vWLEkKosTke/6xDBVZhLS0NP7v//6PF154gQYNGnDgwAGLOgnN0AySFGJiYnBxcaFGjRoA+Pr6cuzYsVwfnJWVFenp6QCkp6fj4OBgiNBEWSJDRBZnz549jB07lqtXr7J3717q168vCeEJGSQppKSk4OTkpLvt5OSkq0D4QI8ePZg+fTq7du3i3r17TJw4Md/XioyMJDIyEoDZs2fj7OxcrJjUanWxn2uuylqb03fv5OavkVgrCtr4i6g96uNYBtpfFj7npKQkRo8ezcaNG2nUqBFbt27Fx8fH2GEZVGl9ziYz0Xzw4EH8/Px4+eWXOX/+PIsXL2b+/Pl5NpcEBgYSGBiou52UlFSs93N2di72c81VWWhzQctLqV0HTct2Ft9+sPzPOScnBz8/Py5dusSIESMYMmQItWrVsug25+dJPmdXV9cCHzNIUnB0dCQ5OVl3Ozk5GUdHx1zX7N27l3HjxgHg5eVFdnY2aWlpVKlSxRAhCgvwaDkKvLyxD3iB9JYdjBuYKBE3btzAyckJlUrFxIkTqV27No0bNzZ2WBbHIHu8PT09SUxM5Pr162g0Gg4dOpSnq+fs7MyZM/d/s4uPjyc7O5vKlSsbIjxh5rRRu8iZO06XEKz6DkQ1eiaq0TOx69rtMc8Wpk5RFL766is6derEl19+CUDXrl0lIZQSg/QUVCoV/fv3Z8aMGWi1Wvz9/XFzc2Pz5s14enri4+NDv379WLFiBT/88AMAAwcOlM0mQi+6lUWymsji/PPPP4wePZqDBw/Srl07OnbsaOyQLJ6VoiiKsYN4EgkJCcV6nqWPu+bHktqc59SzAlYWWVKb9WUpbd6yZQvjxo1DpVIxYcIEevfuXWABO0tpc1GY9ZyCECWhwElkOfXMIrm4uNC+fXtmzZpV6JeYKFmSFITZkBpFli0rK4ulS5ei1WoZNWoUnTp1olMnSfaGpndSOH36NAcPHuT27duMHTuW2NhYMjIy5Pg6YViyAc0inTx5klGjRvHXX3/x+uuvSwE7I9Jr9dGPP/7IypUrqVmzJv/9738BKFeuHJs2bSrV4ISA/60u4vIFY4ciSlhGRgZTp07l5Zdf5tatW0RERLBo0SJJCEakV1L4v//7PyZOnEi3bt10Ez21atUq9iSvEPrS7T04f0bmDizQpUuXiIiIoFevXuzbt4+uXbsaO6QyT6/ho4yMjDzbqTUaDWq1TEmI0vPwZjQ5CtNypKam8uOPP/Lmm2/qCtjJSWimQ6+eQqNGjdi5c2eu+3788UeaNGlSKkEJIQnBMkVGRuLv709ISAgxMTEAkhBMjF5JoX///vz2228MGjSIzMxMhg0bxuHDhwkKCirt+EQZJAnB8iQnJzN48GCCgoKoWrUq3377LfXq1TN2WCIfeo3/ODg4MGvWLGJjY3X1R+rVq1fgRhIhnsSDvQiSECxDTk4O3bp14/Lly4SEhDBo0CDKlStn7LBEAfT6Vp8zZw5WVlbUq1ePdu3a4eXlhbW1NfPmzSvt+EQZkmuVkZe3JAQzd/36dbRaLSqVikmTJrFr1y5GjBghCcHE6ZUUzp49W6T7hSiOhzenySoj86XValm/fj0dO3Zk/fr1ADzzzDM0bNjQyJEJfRQ6fLR582bg/kqjBz8/cO3aNapVq1Z6kYkyQ1e+opAaRsI8XLhwgdGjR3P48GHat2+Pn5+fsUMSRVRoUnhwBoJWq811HgLcL8bUs2fP0otMlAmPnoEgPQTztXnzZsaNG4eNjQ1z587l7bfflk1oZqjQpDBw4EDg/qE3D592JsST0vUO/i1sJ5PK5s/V1ZXOnTszY8YMatasaexwRDHptfroQULIyMggLS2Nh6tt16hRo3QiExZNzkAwf/fu3WPJkiVotVpGjx5Nx44d5bwDC6BXUoiPj2fRokX8888/eR57dK5BCL3J/IHZOn78OCEhIfz999/06NFDCthZEL1WH61atYomTZrwxRdfYGdnR0REBM888wyDBg0q7fiEECYkPT2dKVOm8Morr5CamsratWtZuHChJAQLoldS+Oeff+jduzcVK1ZEURTs7Ozo06eP9BKEKGPi4+NZt24dffv2Zd++fTLXaIH0Sgo2Njbk5OQAYG9vT1JSEoqicOfOnVINTlgmbdSu/52cJkze7du32bhxI3B/0cmBAweYNWsW9vb2Ro5MlAa95hQaNmzI4cOH8fPzo23btsycORMbGxspiCeKLFddI1l+avJ++uknwsLCSEpK4umnn6ZevXpyNKaF0yspjBw5Uvfz22+/jZubG5mZmXTu3LnUAhOWRwrdmY+kpCQmTpzIt99+S6NGjYiIiJACdmVEkQ9EsLa2plOnTmg0GiIjI3nuOfmHLfQjhe7MQ05ODq+++ioJCQmEhoYycOBAbGxsjB2WMJDHJoU///yTixcv4uLiQuvWrcnJyeGnn37im2++oVKlSpIUhF508whS6M5kXb16lerVq6NSqZg6dSpubm54eXkZOyxhYIUmhZ07d/L111/j5ubG5cuXefbZZzl79iw2NjZ8+OGHtGzZ0lBxCjOi2638sAc7l2UeweQ8KGA3c+ZMwsLCCA4OJiAgwNhhCSMpNClERkYSHh5O3bp1OX/+PBMnTqRfv368+OKLhopPmKGHi9vpyM5lkxQbG0toaChHjhyhY8eOdOnSxdghCSMrNCmkpaVRt25d4P5SNBsbG1544QWDBCbMnOxWNnlfffUVEyZMoHz58ixYsICePXvKJjTx+DkFRVF0tY4eTDZptVrd43L6mhDmqXbt2vj7+zNjxgypYSZ0Ck0KmZmZvPXWW7nue/S27GoWwjzcu3ePhQsXAjBmzBgpYCfyVWhSWLJkiaHiEBbg0cNyhOk4duwYISEhxMTE8NZbb0kBO1GgQpOCnKwm9CWH5Zimu3fv8vHHH/PFF1/g6urKhg0b5DQ0Uagib14rrpMnTxIREYFWqyUgIIBu3brluebQoUNs3boVKysr3N3dGTZsmKHCE09INqaZpitXrvDll18SHBzM2LFjqVSpkrFDEibOIElBq9WyevVqJkyYgJOTE2FhYfj4+FC7dm3dNYmJiezcuZNp06ZRqVIlbt++bYjQREmSjWkm4ebNm3z55Zf06dMHLy8vDh06hIuLi7HDEmbCIEuHYmJicHFxoUaNGqjVanx9fTl27Fiua/bs2cOzzz6r+02mSpUqhghNCIvy448/0rx5c8aNG0dMTAyAJARRJEXqKSQlJZGSklLkre8pKSk4OTnpbjs5OREdHZ3rmoSEBAAmTpyIVqulR48eNG/ePM9rRUZGEhkZCcDs2bNxdnYuUiwPqNXqYj/XXJVWm9N37yTt/BlsmrTA0cT+TMvK53z16lVGjBjB9u3bad68OTt37qRFixbGDstgysrn/LDSarNeSSEpKYlPP/2UixcvArB+/XqOHDnCyZMnGTBgQIkEotVqSUxMZPLkyaSkpDB58mTmzZtHxYoVc10XGBiY62CPpKSkYr2fs7NzsZ9rrkqrzTl7/g8ATct2JvdnWhY+55ycHDp37kxiYiJjx45lwoQJ3L592+Lb/bCy8Dk/6knaXFj5c72Gjz7//HNatGjB2rVrUavv55GmTZty+vRpvQJwdHQkOTlZdzs5ORlHR8c81/j4+KBWq6levTo1a9YkMTFRr9cXxiOF7ownISEBrVaLSqVi2rRp7N69myFDhkhFU/FE9EoKMTExdOvWLdfuZTs7O9LT0/V6E09PTxITE7l+/ToajYZDhw7h4+OT65qnn36as2fPApCamkpiYqLssjRh2qhd5MwdJwfmGIFWq+WLL76gc+fOrFu3DoAuXbrIeQeiROg1fFSlShWuXr2aq8sRHx+v93iWSqWif//+zJgxA61Wi7+/P25ubmzevBlPT098fHxo1qwZp06dYsSIEVhbW9OnTx857s+E6TapSaE7g4qJiSEkJIRjx47h5+cnZySLEqdXUnj55Zf5+OOP6datG1qtlgMHDrBjx4589xoUpGXLlnlKbb/55pu6n62srAgKCiIoKEjv1xRGJkXvDGrjxo1MmDCBChUqsHDhQt544w3ZlSxKnF5JoUuXLtjb2xMZGYmTkxNRUVG8+eabPP3006UdnzAB+Z6PIKUsDM7d3Z3AwEBmzJgh1QZEqdErKWi1Wlq3bk3r1q1LOx5hgvKtZ+TmIfMIpSwzM5NPPvkEgLCwMNq3b0/79u2NHJWwdHolhffff5927drRoUMHGjZsWNoxCROQq3fwb0KQoSLDOXbsGKNGjSI2NpZevXpJATthMHolhQkTJnDw4EE+/fRTrK2tad++PR06dOA///lPaccnjODR4nbSKzCcO3fuMHv2bNasWUPt2rXZuHEjnTt3NnZYogzRKyl4eHjg4eFBnz59OHfuHAcOHCA8PBwHBwfmzZtX2jEKA5PidsaTmJjIV199Rf/+/RkzZkyezZtClLYiF8RzdXWldu3axMbGcvXq1dKISRiRbEYzvJSUFL777juCgoKoX78+hw4dkj06wmj0Sgp3797l6NGjHDhwgOjoaJo2bcqrr76aZwOaMD95VhadPwPIZjRDUBSFH374gfHjx3Pr1i3at29PvXr1JCEIo9IrKXz44Yc0aNCADh06MGrUKOnSmrlcieDfJICXt+7/shmt9F27do3x48fz448/0rRpUzZu3Cg7koVJ0CspLF68GAcHh9KORRhIriWmkgQMLicnh+7du3P16lUmTJjA+++/r6spJoSxFfg38dy5czRu3Bi4f3rTlStX8r3O29u7dCITJS599877FU1lialRXLlyhZo1a6JSqZgxYwZubm54enoaOywhcikwKaxevZr58+cDsGzZsnyvsbKyYsmSJaUTmShxmVE/6xKCzBkYTk5ODmvWrGHWrFlMmDCB4OBgOSdZmKwCk8KDhACwdOlSgwQjDEB6CAYVHR3NqFGj+OOPP+jSpQvPPPOMsUMSolB6lc6eM2dOvvfLHgUhCvbll1/StWtX4uLiWLRoEevWraNWrVrGDkuIQumVFB6cc6Dv/cL0aKN2kX32hLHDKFM8PDx47rnn2L9/P6+//rqUqRBmodAlD5s3bwZAo9Hofn7g2rVrUqnRTDxctkLmEkpPRkYGCxYswMrKinHjxkkBO2GWCk0KD47Q1Gq1uY7ThPvng/bs2bP0IhNPTLcf4d+9CPYfhZLesoORo7JMR44cISQkhAsXLtC3b18pYCfMVqFJYeDAgQB4eXnJCU9m6NHT0ey6diO9jB1uXtrS0tKYOXMm69atw93dnc2bN9OhgyReYb4KTArXr1+nevXqADz11FNcu3Yt3+tkS76Jk9VGperatWts2bKFDz74gNGjR2NnZ2fskIR4IgUmhZCQEN2h4EOHDi3wBR6daxDGld85CKJkpaSk8O233xIcHEy9evU4cuSIzK8Ji1FgUniQEEC++M2FnINQuhRF4dtvv2XixImkpqbSsWNHPD09JSEIi1KsgivXrl3DyspKN7wkTIOcg1B6rl69SlhYGLt376ZZs2bMnz9fSlQIi6RXUli4cCHPP/88DRo0YN++faxatQpra2veeecdunTpUtoxisfQDRn9O6ksCaFk5eTk8Prrr3P16lUmTpzIe++9JwXshMXS62/2mTNnGDx4MADff/89EydOpGLFisydO1eSggl4uOqpDBeVnPj4eF0Bu5kzZ/Kf//wHDw+ZoxGWTa8dzRqNBrVaTUpKCnfu3KFhw4a4ublx+/bt0o5PFEIbtYucueNyVT2VXsKTy8nJYcWKFXTu3Fk3t9a5c2dJCKJM0KunUKdOHXbs2MGNGzdo2bIlcH8FRoUKFUo1OFE46SGUvL/++ouQkBBOnDhBYGAgzz77rLFDEsKg9OopDBgwgEuXLpGVlcWbb74JwPnz52WTjhHpzlKWHkKJWbduHc899xz//PMPS5cuZc2aNbi6uho7LCEMSq+egouLC8OGDct1X9u2bWnbtm2pBCUeT7fSSHoIT+xBSYr69evz0ksvER4ejpOTk7HDEsIo9F5CsW/fPqKiokhJScHR0ZFOnTrh7+9fmrGJfMhKo5KTkZHB3LlzUalUjB8/nnbt2tGuXTtjhyWEUemVFLZv384vv/zCyy+/jLOzM0lJSXz77bfcvHmT7t27l3aM4iEyj1AyDh06xOjRo7l48SJBQUFSwE6If+mVFPbs2cbawp8AAB6sSURBVMOUKVNy7dxs1qwZkydPlqRgDFLPqNhSU1OZPn06GzZsoE6dOmzZskXKWwvxEL2Swr1796hcuXKu++zt7cnKyiqVoEReuYaNpJ5RsV2/fp3t27czYMAAQkJCZAWdEI/Qa/VR8+bNWbRoEQkJCWRlZXHlyhWWLFlCs2bN9H6jkydPMmzYMIYMGcLOnTsLvO7IkSP07NmT2NhYvV+7LJBho+JLTk7miy++AKBevXocPXqUiRMnSkIQIh969RT69+/PF198QUhICDk5OajVatq1a8c777yj15totVpWr17NhAkTcHJyIiwsDB8fH2rXrp3ruoyMDH788Ufq169f9JaUBTJsVCSKorBp0yaGDx/OnTt36Ny5M56enrKySIhCPDYppKenc/XqVd59910GDhxIWloa9vb2WFvr1ckAICYmBhcXF93ZC76+vhw7dixPUti8eTOvvvoq3377bRGbYZmkDHbxXblyhbCwMPbs2UOLFi2kgJ0Qeio0KRw/fpxPPvmErKwsbG1tGT16NN7e3kV+k5SUlFy/nTk5OREdHZ3rmri4OJKSkmjZsmWhSSEyMpLIyEgAZs+ejbOzc5HjAVCr1cV+rqGkHD+MJv4iao/6UNcL207PYPcEMZtDm0uCRqOhQ4cOXLt2jQULFjBgwABUKpWxwzKYsvI5P0zaXIKvW9iDmzdvpnfv3vj7+7Nnzx42bdrE9OnTSzwIrVbLunXrdMd/FiYwMDDX0aBJxTxe8sHSWlP06KSydng4AOnwRMdpmnKbS8Lly5dxdXXVFbBzd3enVatWFt3m/Fj655wfaXPRFLZTv9AxoGvXrvHcc89Rvnx5nn32Wa5evVqsABwdHUlOTtbdTk5OxtHRUXc7MzOTy5cvEx4ezqBBg4iOjmbOnDlldrJZJpWLRqPRsHz5cvz8/Fi7di0AnTp1wt3d3ciRCWF+Cu0pKIqi+1mlUpGTk1OsN/H09CQxMZHr16/j6OjIoUOHch3xaWdnx+rVq3W3p0yZQt++fcv2GLBMKuvl3LlzhISEcOrUKZ599lleeOEFY4ckhFkrNCncu3ePyZMn625nZmbmug0QHh7+2DdRqVT079+fGTNmoNVq8ff3x83Njc2bN+Pp6YmPj08xw7c8ukJ3XkWfuylr1qxZw+TJk6lSpQrLli3j5Zdfll3JQjyhQpPCgAEDct1+klpHLVu21JXdfuBBxdVHTZkypdjvY+6k0N3jPShJ0bBhQ1555RXCw8NzDUcKIYqv0KTg5+dnoDBELlLoLl/p6el8/PHHqNVqJk6cKJV6hSgF+m82EKVON3Qk8vj1118JCAhg1apVZGVl5ZrvEkKUHDl93ERoo3ahrP8MkKGjh92+fZtp06bx1Vdf4eHhwfbt22nTpo2xwxLCYklSMAG5EkLfgTJ09JAbN27wzTffMGjQIEaMGCH1ioQoZZIUjEwSQl4PEsF7772nK2AnE8lCGIZeSSE7O5tt27Zx8OBB0tLSWLt2LadOnSIxMZHnnpMvsSehW20kCQFFUdi+fTuTJk0iPT2dLl26ULduXUkIQhiQXhPNa9eu5fLlywwdOlS3DtzNzY3du3eXanCWTBu1i5y54+RYzX9duXKFfv36MXToUDw9Pdm9ezd169Y1dlhClDl69RR+++03Fi1ahK2trS4pODo6kpKSUqrBWaqHh4zw8i7zE8sajYY33niDpKQkpk2bRlBQUJkqYCeEKdErKajVarRaba77UlNTsbe3L5WgLJWu0N2/y07L+pDRP//8Q+3atVGr1cyZM4c6derg5uZm7LCEKNP0Sgpt27ZlyZIlBAcHA3Dz5k3WrFmDr69vacZmEXKdifBgD8K/vYOymhA0Gg0rVqxg/vz5jB8/nnfffZeOHTsaOywhBHomhV69evHll18yatQosrKyGDp0KAEBAfTo0aO04zN7uc5VLuPJAODMmTOEhITw559/8vzzz/PSSy8ZOyQhxEP0Hj4KDg4mODhYN2wkhceKQCqeAhAREcGUKVNwcHDg888/58UXXzR2SEKIR+iVFK5du5brdkZGhu7nB0dsClGQBwXsGjVqxGuvvcbkyZNxcHAwdlhCiHzolRQePvvgUZs3by6xYCxNWS+DfffuXV0Bu0mTJkkBOyHMgF5J4dEv/lu3brF161YaNWpUKkFZirJcBvuXX34hNDSUK1eu0L9/f11vQQhh2opVJbVq1aoEBwezcePGko7H8pSxjWm3bt1ixIgR9OrVi/Lly7N9+3amTp0qCUEIM1Hs2kcJCQncu3evJGMRFiApKYkffviBwYMHM2LECGxtbY0dkhCiCPRKCpMmTcr1m969e/e4fPkyb7zxRqkFZs50exMeLEW1cNevX2fnzp188MEH1KtXjyNHjki9IiHMlF5JoUuXLrlu29ra4u7uTs2aNUslKHP3cEKw5PkERVHYunUr4eHhZGRkEBgYKAXshDBzj00KWq2WM2fO8OGHH2JjY2OImMzawyuOLHlvwuXLlxkzZgy//PILrVu3Zt68eVLATggL8NikYG1tzenTp2WiUE9lYcWRRqOhR48epKSkMGPGDPr164e1tZzsKoQl0Otf8osvvsiWLVvQaDSlHY9lsNAVRxcuXCAnJwe1Ws38+fPZu3cvwcHBkhCEsCCF9hQOHDhAhw4d2LVrF7du3eKHH36gcuXKua5ZtmxZqQZoTix1s1p2djbLli3jk08+YcKECbz77ru0b9/e2GEJIUpBoUlh5cqVdOjQgSFDhhgqHrNmiUNHf/75J6NGjeLs2bO89NJLvPLKK8YOSQhRigpNCoqiANC4cWODBGMRLGjoaPXq1YSHh+Pk5MSqVat4/vnnjR2SEKKUFZoUHqw8Koy3t2UNlRSHpe1LeFCSwtvbmzfeeINJkyZRtWpVY4clhDCAQpNCdnY2y5cv1/UYHmVlZcWSJUtKJTBzYUlHa965c4dZs2ZRrlw5Jk+eTJs2bWjTpo2xwxJCGFChScHW1rbMf+kX5uGEYO5Ha+7bt48xY8aQkJDAe++9JwXshCijil37SDw0sWzGCSElJYXw8HC2bdtG/fr12blzJz4+PsYOSwhhJHpNNItCmPnE8s2bN9m1axfDhw9n6NChlC9f3tghCSGMqNCksG7duhJ7o5MnTxIREYFWqyUgIIBu3brlevz7779nz549qFQqKleuzEcffUS1atVK7P3F/1y7do0dO3bw4Ycf4unpydGjR2UiWQgBFPM8haLSarWsXr2acePG8cknn3Dw4EHi4+NzXVOnTh1mz57NvHnzaNu2LV9++aUhQis23UY1M6IoCps2bcLPz4+5c+dy4cIFAEkIQggdgySFmJgYXFxcqFGjBmq1Gl9fX44dO5brGm9vb93QRf369UlJSTFEaEWmjdpFztxx/5tgNpPVRpcuXeKFF15g1KhRNG7cmN27d0sBOyFEHgaZaE5JScHJyUl328nJiejo6AKv37t3L82bN8/3scjISCIjIwGYPXs2zs7OxYpJrVYX67kpxw+jib+IukkLbDs9g13Xbo9/kpFpNBp8fX1JSUlh8eLFvPfee2WmXlFxP2dzJm0uG0qrzSa3+igqKoq4uDimTJmS7+OBgYEEBgbqbiclJRXrfZydnYv13JzsbKhdB+3wcNKB9GK+vyHExcXh7u6OSqVi3rx5tGjRggoVKphsL6w0FPdzNmfS5rLhSdrs6upa4GMG+XXR0dGR5ORk3e3k5OR8D2I5ffo0O3bsIDQ0VM5ueALZ2dksXLiQgIAAIiIiAPD19cXNzc3IkQkhTJ1BkoKnpyeJiYlcv34djUbDoUOH8qyFv3DhAitXriQ0NJQqVaoYIqwiM4fJ5VOnTvH8888zd+5cnn/++TyrvIQQojAGGT5SqVT079+fGTNmoNVq8ff3x83Njc2bN+Pp6YmPjw9ffvklmZmZLFiwALjfNRozZowhwtNLrt3LJjq5vGrVKsLDw6levToRERF07drV2CEJIcyMlWLmO9QSEhKK9byijMeZejmLByUpjh07xtatWxk/fny+vS0Zdy0bpM1lQ2nNKZjcRLMpMtVyFmlpacyYMYPy5csTHh5O69atad26tbHDEkKYsbKxLrEkmFg5iz179uDv78+GDRtQq9VSkkQIUSKkp1AIUzwnISUlhcmTJ7N9+3YaNGjA559/TsuWLY0dlhDCQkhSKMTDCcFUJpdv3brFzz//zMiRIxkyZAjlypUzdkhCCAsiSeFx3DxQjZ5p1BASExPZsWMHH330EXXr1uXo0aMmu2xXCGHeZE7BhCmKwoYNG/D392f+/PlcvHgRQBKCEKLUSFIwURcvXqRnz56Ehobi7e1NZGQkHh6mMa8hhLBcMnxUAN3uZS9vg7+3RqPhzTff5NatW3z88cf06tWrzBSwE0IYlySFAuj2JhhwgjkmJoY6deqgVqtZuHAh7u7uhW4yEUKIkia/fhbGQHsTsrKyWLBgAYGBgaxZswaAdu3aSUIQQhic9BSM7MSJE4SEhPDXX3/x2muv0b17d2OHJIQowyQpGNHKlSuZOnUq1atXZ82aNTzzzDPGDkkIUcbJ8JERPChJ0bx5c3r16sW+ffskIQghTIL0FPJRWiuPUlNTmT59Ora2tkydOlUK2AkhTI70FB5RWucm7N69G39/f7766ivKly8vBeyEECZJegoPKY1zE5KTk5k0aRI7d+6kUaNGrF69mubNmz/x6wohRGmQpPCQ0jg3ITU1lb179xISEsKgQYOkgJ0QwqRJUnhUCexNuHLlCtu3b2fw4MF4eHhw9OhRKleuXEIBCiFE6ZE5hRKk1WpZt24dXbp04dNPP9UVsJOEIIQwF5IUSkhcXBw9e/YkLCyM5s2bs2fPHilgJ4QwOzJ8VAI0Gg1vv/02qampzJ8/nzfffBMrKytjhyWEEEUmSeEJREdH4+HhgVqtZtGiRbi7u+Pi4mLssIQQotjK/PCRNmoXOXPHkTN33P2jN/Vw79495s2bR2BgIBEREQC0adNGEoIQwuyV+Z7Cw+cw63MW8x9//EFISAjnz5/n9ddf5/XXXzdQpEIIUfrKfFIA9D6Hefny5UyfPp2aNWuyfv16unTpYoDghBDCcMr88JE+tFotAK1ataJv377s3btXEoIQwiJJT6EQt2/fZurUqVSoUIHp06dLATshhMWTnkIBdu3ahb+/P1u3bqVixYpSwE4IUSZIT+ERSUlJjB8/nu+//54mTZqwdu1annrqKWOHJYQQBlGmewq6cxMekpaWxq+//sqYMWP44YcfJCEIIcqUMp0UHlRFve3VlE8//RRFUfDw8OC3335j6NCh2NjYGDlCIYQwLIMNH508eZKIiAi0Wi0BAQF069Yt1+PZ2dksWbKEuLg47O3tGT58ONWrVy+1eNJ374TzZ7ha2Rn/0ZPQarW88soreHh4UKlSpVJ7XyGEMGUG6SlotVpWr17NuHHj+OSTTzh48CDx8fG5rtm7dy8VK1Zk8eLFvPjii2zYsKFUY7q56xsAFh78g1atWrFv3z4pYCeEKPMMkhRiYmJwcXGhRo0aqNVqfH19OXbsWK5rfv/9d/z8/ABo27YtZ86cKbUVP5qNK1Bf+JtjtzPwGTGOjRs34ubmVirvJYQQ5sQgw0cpKSk4OTnpbjs5OREdHV3gNSqVCjs7O9LS0vKcRRAZGUlkZCQAs2fPxtnZucjxpFWsSLKbJ616BfJSj6AiP99cqdXqYv15mTNpc9kgbS7B1y3xVyxlgYGBBAYG6m4nJSUV/UVe7UOdd4eTlJRUvOebKWdn5zLVXpA2lxXS5qJxdXUt8DGDDB85OjqSnJysu52cnIyjo2OB1+Tk5JCeno69vb0hwhNCCPEvgyQFT09PEhMTuX79OhqNhkOHDuHj45PrmlatWrF//34Ajhw5QpMmTeSgGiGEMDCDDB+pVCr69+/PjBkz0Gq1+Pv74+bmxubNm/H09MTHx4cuXbqwZMkShgwZQqVKlRg+fLghQhNCCPEQK8XMi/okJCQU63kyBlk2SJvLBmlz0Rh9TkEIIYR5kKQghBBCR5KCEEIIHUkKQgghdMx+olkIIUTJKbM9hbFjxxo7BIOTNpcN0uayobTaXGaTghBCiLwkKQghhNBRTZkyZYqxgzCWunXrGjsEg5M2lw3S5rKhNNosE81CCCF0ZPhICCGEjiQFIYQQOmZ3yE5RnTx5koiICLRaLQEBAXTr1i3X49nZ2SxZsoS4uDjs7e0ZPnw41atXN1K0JeNxbf7+++/Zs2cPKpWKypUr89FHH1GtWjUjRVsyHtfmB44cOcKCBQuYNWsWnp6eBo6yZOnT5kOHDrF161asrKxwd3dn2LBhRoi05DyuzUlJSSxdupS7d++i1Wrp1asXLVu2NFK0T+6zzz7j+PHjVKlShfnz5+d5XFEUIiIiOHHiBOXLl2fgwIFPPs+gWLCcnBxl8ODBytWrV5Xs7GwlJCREuXz5cq5rdu3apaxYsUJRFEU5cOCAsmDBAmOEWmL0afOff/6pZGZmKoqiKD/99FOZaLOiKEp6eroyadIkZdy4cUpMTIwRIi05+rQ5ISFBGT16tJKWlqYoiqLcunXLGKGWGH3avHz5cuWnn35SFEVRLl++rAwcONAYoZaYs2fPKrGxscrIkSPzffyPP/5QZsyYoWi1WuXvv/9WwsLCnvg9LXr4KCYmBhcXF2rUqIFarcbX15djx47luub333/Hz88PgLZt23LmzBkUM55716fN3t7elC9fHoD69euTkpJijFBLjD5tBti8eTOvvvoqNjY2RoiyZOnT5j179vDss89SqVIlAKpUqWKMUEuMPm22srIiPT0dgPT0dBwcHIwRaolp3Lix7vPLz++//06nTp2wsrLCy8uLu3fvcvPmzSd6T4tOCikpKTg5OeluOzk55fkCfPgalUqFnZ0daWlpBo2zJOnT5oft3buX5s2bGyK0UqNPm+Pi4khKSjLroYSH6dPmhIQEEhMTmThxIuPHj+fkyZOGDrNE6dPmHj168OuvvzJgwABmzZpF//79DR2mQaWkpODs7Ky7/bh/7/qw6KQgChcVFUVcXByvvPKKsUMpVVqtlnXr1tGvXz9jh2JQWq2WxMREJk+ezLBhw1ixYgV37941dlil6uDBg/j5+bF8+XLCwsJYvHgxWq3W2GGZFYtOCo6OjiQnJ+tuJycn4+joWOA1OTk5pKenY29vb9A4S5I+bQY4ffo0O3bsIDQ01OyHUx7X5szMTC5fvkx4eDiDBg0iOjqaOXPmEBsba4xwS4S+f7d9fHxQq9VUr16dmjVrkpiYaOhQS4w+bd67dy/t2rUDwMvLi+zsbLPu+T+Oo6NjrtPXCvr3XhQWnRQ8PT1JTEzk+vXraDQaDh06hI+PT65rWrVqxf79+4H7K1OaNGmClZWVEaItGfq0+cKFC6xcuZLQ0FCzH2eGx7fZzs6O1atXs3TpUpYuXUr9+vUJDQ0169VH+nzOTz/9NGfPngUgNTWVxMREatSoYYxwS4Q+bXZ2dubMmTMAxMfHk52dTeXKlY0RrkH4+PgQFRWFoiicP38eOzu7J55HsfgdzcePH2ft2rVotVr8/f3p3r07mzdvxtPTEx8fH7KysliyZAkXLlygUqVKDB8+3Kz/4cDj2zxt2jQuXbpE1apVgfv/kMaMGWPkqJ/M49r8sClTptC3b1+zTgrw+DYrisK6des4efIk1tbWdO/enfbt2xs77CfyuDbHx8ezYsUKMjMzAejTpw/NmjUzctTFt3DhQs6dO0daWhpVqlShZ8+eaDQaALp27YqiKKxevZpTp05Rrlw5Bg4c+MR/ry0+KQghhNCfRQ8fCSGEKBpJCkIIIXQkKQghhNCRpCCEEEJHkoIQQggdSQrCrEyZMoU9e/YYO4xC/frrr0yfPr3Ax//73/+afbVSYblkSaowmkGDBnHr1i2srf/3u8mnn35a6I7MKVOm0LFjRwICAkosjilTphAdHY21tTXlypWjUaNGvPvuuyVWTK1nz54sWrQIFxeXEnm9gmzZsoUdO3agVqtRqVTUrl2bfv364eXlZVJxCtNm8ecpCNM2ZswYmjZtauww6N+/PwEBAdy5c4f58+ezdu1ahg8fbuywiqxdu3YMHTqUnJwctmzZwoIFC1i+fLmxwxJmRJKCMCl37txhyZIlREdHo9VqadCgAe+//36u6pgPXL16lWXLlnHx4kXUajXe3t6MGDECgCtXrvDFF18QFxdH5cqVefPNN/H19X3s+1eqVIk2bdrw888/A/D333+zZs0aEhIScHV1JTg4mAYNGgCwf/9+tm3bRmpqKvb29rz11lt07NiR/fv3s2fPHqZNm8bkyZMBGD16NAAfffQRVapUYfHixSxfvpydO3cSGxvLqFGjdDFERESgKAr9+/cnPT2dtWvXcuLECaysrPD396dnz565elf5UalUdOzYkR07dpCamkrlypWJiYkhIiKCK1euUK5cOdq0aUNQUBBqtTrfOH19ffnjjz/YtGkTN27coHbt2rz//vu4u7s/9s9RmC9JCsKkKIqCn58fI0aMQKvVsmzZMlavXk1oaGieazdt2kSzZs2YPHkyGo2GuLg44H4BvOnTp9OzZ0/GjRvHpUuXmD59Ov/5z3+oXbt2oe+fmprK0aNHqVOnDnfu3GH27Nm88847tG/fnsOHDzN79mwWLVqEjY0NERERzJo1C1dXV27evMmdO3fyvF54eDg9e/Zk7ty5umGZB/WIANq3b8+2bdvIyMigQoUKaLVaDh8+TEhICABLly6lSpUqLFq0iHv37jF79mycnJx45plnCm2HRqPhl19+wd7enooVKwJgbW1NUFAQnp6eJCcnM2vWLH766SdefPHFfOO8cOECy5YtY8yYMXh6ehIVFcWcOXNYuHCh2RdRFAWTiWZhVHPnziU4OJjg4GDmzJmDvb09bdu2pXz58lSoUIHu3bvz3//+N9/nqtVqbty4wc2bNylXrhwNGzYE7tfHqVatGv7+/qhUKjw8PGjTpg2HDx8uMI6IiAiCg4MZPXo0Dg4OBAUFcfz4cVxcXOjUqRMqlYoOHTrg6urKH3/8Adw/0OXSpUtkZWXh4OCAm5tbkdtfrVo1PDw8+O233wA4c+YM5cuXx8vLi1u3bnHixAmCg4OxtbWlSpUqvPjiixw6dKjA1zt8+DDBwcH07t2bPXv2MHLkSFQqFQB169bFy8sLlUpF9erVCQwM5Ny5cwW+VmRkJIGBgdSvXx9ra2v8/PxQq9VER0cXuZ3CfEhPQRjV6NGjc80p3Lt3j7Vr13Ly5Eld7f+MjAy0Wm2eIZM+ffqwadMmxo0bR8WKFXnppZfo0qULN27cIDo6muDgYN21OTk5dOrUqcA43nnnnTyT1ykpKXnOrq5WrRopKSnY2toyfPhwvvvuO5YvX06DBg3o168ftWrVKvKfQYcOHTh48CCdO3fmwIEDuqJ1SUlJ5OTk8MEHH+iuVRQl36G0Bx7MKaSmpjJ//nzi4uJo0qQJcP/QnXXr1hEbG0tWVhY5OTmFnueblJTEL7/8wq5du3T3aTQasz+pTxROkoIwKd999x0JCQnMnDmTqlWrcvHiRUJDQ/M9IrVq1aoMGDAAgL/++otp06bRuHFjnJycaNy4MRMnTnyiWBwdHTl69Giu+5KSknQn1TVv3pzmzZuTlZXFpk2bWLFiBVOnTi3y+7Rr145169aRnJzMb7/9plvO6uTkhFqtZvXq1brf9vVVuXJlPvzwQ8aOHUuHDh1wcHBg1apV1KlTh2HDhlGhQgV++OEHjhw5UuBrODk50b17d7p3717kNgnzJcNHwqRkZmZSrlw57OzsuHPnDlu3bi3w2sOHD+sOXXkwbm5lZUWrVq1ITEwkKioKjUaDRqMhJiaG+Pj4IsXSokULEhMTOXDgADk5ORw6dIj4+HhatmzJrVu3OHbsGJmZmajVamxtbQs8h6NKlSpcu3atwPepXLkyTZo04bPPPqN69eq6eQ8HBweaNWvGunXrSE9PR6vVcvXq1UKHfB7m6upKs2bN+Oabb4D7PS47OztsbW25cuUKu3fvLjTOgIAAfv75Z6Kjo1EUhczMTI4fP05GRoZe7y/Mk/QUhEl54YUXWLRoEe+++y6Ojo689NJLeQ5nfyA2NpY1a9aQnp5O1apVeeedd3RnYUyYMIG1a9eydu1aFEXB3d2doKCgIsVib2/P2LFjiYiIYOXKlbi4uDB27FgqV67MzZs3+f7771myZAlWVlbUqVOH999/P9/X6dGjB0uXLiUrK4sPPvgg34ONOnTowJIlS+jTp0+u+wcPHsyGDRsYOXIkGRkZ1KhRg1dffVXvNrzyyitMnTqV1157jb59+/L555/zzTff4OHhga+vr+5Amvzi9PX15cMPP+SLL74gMTFRN2/TqFEjvd9fmB/ZvCaEEEJHho+EEELoSFIQQgihI0lBCCGEjiQFIYQQOpIUhBBC6EhSEEIIoSNJQQghhI4kBSGEEDr/D2up4lK5x+KpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import necessary packages\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use(\"ggplot\")\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# create a confusion matrix based on our actual y labels and predicted y labels\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "confmatstr = [\"true negatives\", \"false positives\", \"false negatives\", \"true positives\"]\n",
    "confmat = [tn, fp, fn, tp]\n",
    "# print the counts\n",
    "for i in range(len(confmat)):\n",
    "    print(\"{}: {}\".format(confmatstr[i],confmat[i]))\n",
    "\n",
    "print(\"===================================\")\n",
    "\n",
    "# create an array of measure values\n",
    "measures = precision_recall_fscore_support(y_test,y_pred)\n",
    "measure_names = [\"precision:\",\"recall:\",\"f1-score:\"]\n",
    "# print the measure values\n",
    "for i in range(len(measures)-1):\n",
    "    print(measure_names[i],np.round(measures[i][1],2))\n",
    "\n",
    "print(\"===================================\")\n",
    "\n",
    "y_pred_prob = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# define false positive rate, true positive rate and thresholds\n",
    "fpr, tpr, thresholds= roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# print the area under the (ROC) curve\n",
    "print(\"AUC (Area Under Curve):\",auc(fpr, tpr))\n",
    "\n",
    "# plot the ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
